\section*{Related work}
\label{sec:relatedwork}

\subsection*{Unsupervised anomaly detection}

The majority of recent research on industrial anomaly detection has focused on unsupervised methods due to the challenges and costs associated with collecting labeled abnormal samples. Typically, only normal samples are used in the training set, while both normal and abnormal samples are included in the test set. Before the advent of deep learning, traditional techniques such as differential detection and filtering were frequently used to identify anomalies in industrial images. With the rise of deep learning, anomaly detection methods for industrial images have largely shifted toward two main categories: reconstruction-based and feature-embedding methods.

\subsubsection*{Reconstruction-Based Methods}

The core assumption of reconstruction-based methods is that the model should be able to restore anomalous regions by comparing the reconstructed image to the original. Differences at the anomalous positions enable defect localization. During training, normal or abnormal images are fed into the reconstruction network, with the reconstruction loss function guiding the network's learning process. The trained network is then expected to restore images resembling the original normal images. During inference, a comparison model highlights the discrepancies between the original and reconstructed images to make predictions. Early models include Auto-Encoder (AE) \cite{yu2023unsupervised, collin2021improved}, Variational Auto-Encoder (VAE) \cite{liu2020towards}, and Generative Adversarial Networks (GAN) \cite{akcay2019ganomaly, perera2019ocgan}. For example, Bergmann et al. \cite{bergmann2018improving} explores how the structure similarity index measure (SSIM) affects AE reconstruction and anomaly segmentation. To avoid over-detection, Chung et al. \cite{chung2020unsupervised} proposed the Outlier-Exposed Style Distillation Network (OE-SDN), which focuses on maintaining style translation while limiting content translation in the AE. Structural improvements to AE have also been explored. For instance, Zhou et al. \cite{zhou2020encoding} introduced P-Net to compare structural differences between the original and reconstructed images, while Collin et al. \cite{collin2021improved} incorporated skip-connections between the encoder and decoder to enhance reconstruction sharpness.

VAEs are a variation of AEs, differing in that VAE's intermediate variables are sampled from a normal distribution \cite{liu2020towards, dehaene2020iterative}. To address VAE's tendency to produce blurry reconstructions, \cite{dehaene2020iterative} introduced gradient descent in reconstruction with energy defined by the reconstruction loss, preserving high-frequency structures. VQ-VAE \cite{wang2020image} adds a discrete latent space and resamples the latent codes deviating from normal distributions, improving reconstruction by focusing on closer-to-normal images. Reconstruction models based on GANs have been shown to be less stable than AE-based models, but the discriminative power of GAN's networks can be more effective in specific contexts \cite{ganokratanaa2020unsupervised, ganokratanaa2022video}. SCADN (Semantic Context-based Anomaly Detection Network) \cite{yan2021learning} masks parts of the image during training and reconstructs them using GAN, detecting anomalies by comparing the reconstructed and original images. OCR-GAN \cite{liang2023omni} decouples an image into various frequency components and reconstructs them separately, improving anomaly detection.



 However, while reconstruction-based methods are effective in anomaly detection, their classification performance is limited due to a weaker ability to extract high-level semantic features.

\subsubsection*{Feature-Embedding Methods}

In contrast, feature-embedding methods rely on pre-trained feature extractors to identify anomalies \cite{rudolph2021same, wang2021student}. Features from normal samples typically conform to a known distribution, and deviations from this distribution signal anomalies. Several studies \cite{bergmann2020uninformed, salehi2021multiresolution, wang2021student, cao2022informative} adopt a teacher-student architecture for anomaly detection. In this approach, a backbone network pre-trained on a large-scale dataset serves as the teacher model, which is then used to train the student model to extract features from normal samples. During inference, normal image features from the test set extracted by both networks are similar, but features from abnormal images differ significantly. An anomaly score map is generated by comparing the feature maps from both networks, and when scaled to the input image size, this map indicates the anomaly scores of various regions. Some researchers have framed anomaly detection as a one-class classification (OCC) problem, inspiring enhancements to traditional methods like Support Vector Data Description (SVDD) \cite{tax2004support, defard2021padim}. For example, \cite{yi2021patch, zhang2021anomaly, hu2021semantic} have adapted SVDD for industrial anomaly detection. Another approach leverages memory banks \cite{li2021anomaly, wan2021industrial, roth2022towards} to store representative features. These memory-based methods require minimal network training, relying on pre-sampled normal features for inference. During inference, features from the test image are compared with those in the memory bank, and the distance from the normal features determines the anomaly probability \cite{lee2022cfa, kim2023fapm, defard2021padim}. However, while memory-based methods can be efficient, they tend to have higher memory requirements and longer inference times due to the storage of representative.

\subsection*{Anomaly Detection with Dual Modalities}

RGB images provide rich semantic information, while depth images or point clouds capture essential geometric cues. Many studies have explored how to leverage the complementary nature of these data types across various computer vision tasks. Recently, depth data (or 3D information) has been utilized to improve the robustness and accuracy of anomaly detection systems \cite{horwitz2022empirical, wang2023multimodal}. Bergmann et al. \cite{bergmann2023anomaly} introduced the 3D Student-Teacher (3D-ST) model for unsupervised anomaly detection, which operates directly on 3D point clouds. This method, trained solely on anomaly-free data, identifies geometric anomalies in high-resolution test samples with just a single forward pass. However, the method's effectiveness is limited by the similarity between the student and teacher networks, which leads to small distances even for anomalies. To address this, Rudolph et al. \cite{rudolph2023asymmetric} proposed Asymmetric Student-Teacher networks (AST), where a normalizing flow model is used as the teacher for density estimation, while a conventional feed-forward network serves as the student. This architecture induces larger distances for anomalies. The AST approach is extendable to multimodal inputs, including RGB and 3D data, by concatenating depth maps with RGB features along the channels when 3D data is available. Horwitz et al. \cite{horwitz2023back} explored the integration of geometric features with visual features for anomaly detection, examining a wide range of both hand-crafted and deep learning-based representations. Their findings indicated that hand-crafted descriptors from point clouds provided the most effective results. Building on this, Wang et al. \cite{wang2023multimodal} enhanced the approach by utilizing more informative visual and geometric features extracted from pre-trained models on large datasets. They introduced a learned function to fuse visual and geometric features into unified multimodal representations, which were stored in memory banks along with features from each individual modality. However, this method's dependence on extensive feature banks made it resource-intensive. In contrast to these approaches, our proposed method does not fuse visual and geometric features directly. Instead, it learns to map visual features to their corresponding geometric features. By reconstructing geometric features from visual inputs using pre-trained models, our approach significantly reduces memory usage and enhances inference speed, while maintaining high effectiveness in anomaly detection.